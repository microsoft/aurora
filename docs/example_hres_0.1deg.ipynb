{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f57a10-13a1-4f66-a734-065fc16b17b2",
   "metadata": {},
   "source": [
    "# Example: Predictions for HRES at 0.1 deg\n",
    "\n",
    "In this example, we will download HRES data for 11 May 2022 from the [Research Data Archive](https://rda.ucar.edu/datasets/d113001/#) at 0.1 degree resolution and run Aurora on this data. We will use the version of Aurora that was fine-tuned on IFS HRES 0.1 degree.\n",
    "\n",
    "Running this notebook requires additional Python packages. You can install these as follows:\n",
    "\n",
    "```\n",
    "pip install xarray zarr netcdf4 cfgrib scipy matplotlib\n",
    "```\n",
    "\n",
    "\n",
    "## Downloading the Data\n",
    "\n",
    "To start, we download the data from [Research Data Archive](https://rda.ucar.edu/datasets/d113001/#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f355c242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msl already downloaded\n",
      "10u already downloaded\n",
      "10v already downloaded\n",
      "2t already downloaded\n",
      "z at time 00 already downloaded\n",
      "z at time 06 already downloaded\n",
      "z at time 12 already downloaded\n",
      "z at time 18 already downloaded\n",
      "t at time 00 already downloaded\n",
      "t at time 06 already downloaded\n",
      "t at time 12 already downloaded\n",
      "t at time 18 already downloaded\n",
      "u at time 00 already downloaded\n",
      "u at time 06 already downloaded\n",
      "u at time 12 already downloaded\n",
      "u at time 18 already downloaded\n",
      "v at time 00 already downloaded\n",
      "v at time 06 already downloaded\n",
      "v at time 12 already downloaded\n",
      "v at time 18 already downloaded\n",
      "q at time 00 already downloaded\n",
      "q at time 06 already downloaded\n",
      "q at time 12 already downloaded\n",
      "q at time 18 already downloaded\n",
      "z already downloaded\n",
      "lsm already downloaded\n",
      "slt already downloaded\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "from aurora.util import download_hres_rda_atmos, download_hres_rda_static, download_hres_rda_surf\n",
    "\n",
    "# Data will be downloaded here.\n",
    "download_path = Path(\"~/downloads/hres_0.1\")\n",
    "\n",
    "download_path = download_path.expanduser()\n",
    "download_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Day to download. This will download all times for that day.\n",
    "day = \"11\"\n",
    "month = \"05\"\n",
    "year = \"2022\"\n",
    "\n",
    "# Each variable has a number associated with it. This is the number that\n",
    "# will be used in the RDA request.\n",
    "var_nums = {\n",
    "    \"msl\": \"151\",  # Mean sea level pressure\n",
    "    \"10u\": \"165\",  # 10m u-component of wind\n",
    "    \"10v\": \"166\",  # 10m v-component of wind\n",
    "    \"2t\": \"167\",  # 2m temperature\n",
    "    \"z\": \"129\",  # Geopotential\n",
    "    \"t\": \"130\",  # Temperature\n",
    "    \"u\": \"131\",  # u-component of wind (atmos)\n",
    "    \"v\": \"132\",  # v-component of wind (atmos)\n",
    "    \"q\": \"133\",  # Specific humidity (atmos)\n",
    "    \"slt\": \"043\",  # Soil type\n",
    "    \"lsm\": \"172\",  # Land sea mask\n",
    "}\n",
    "\n",
    "surface_vars = [\"msl\", \"10u\", \"10v\", \"2t\"]\n",
    "atmos_vars = [\"z\", \"t\", \"u\", \"v\", \"q\"]\n",
    "static_vars = [\"z\", \"lsm\", \"slt\"]\n",
    "\n",
    "# Download surface variables. We write the downloaded data to cache.\n",
    "for variable in surface_vars:\n",
    "    if not (download_path / f\"{variable}_{year}_{month}_{day}.grb\").exists():\n",
    "        download_hres_rda_surf(\n",
    "            save_dir=download_path,\n",
    "            year=year,\n",
    "            month=month,\n",
    "            day=day,\n",
    "            variable=variable,\n",
    "            var_dict=var_nums,\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{variable} already downloaded\")\n",
    "\n",
    "# Download atmospheric variables. We write the downloaded data to cache.\n",
    "# Each variable has 4 times per day, each of which is a separate file.\n",
    "# This will take a few minutes.\n",
    "for variable in atmos_vars:\n",
    "    for timeofday in [\"00\", \"06\", \"12\", \"18\"]:\n",
    "        if not (download_path / f\"{variable}_{year}_{month}_{day}_{timeofday}.grb\").exists():\n",
    "            download_hres_rda_atmos(\n",
    "                save_dir=download_path,\n",
    "                year=year,\n",
    "                month=month,\n",
    "                day=day,\n",
    "                variable=variable,\n",
    "                var_dict=var_nums,\n",
    "                timeofday=timeofday,\n",
    "            )\n",
    "        else:\n",
    "            print(f\"{variable} at time {timeofday} already downloaded\")\n",
    "\n",
    "# Download static variables. We write the downloaded data to cache.\n",
    "for variable in static_vars:\n",
    "    if not (download_path / f\"static_{variable}.grb\").exists():\n",
    "        download_hres_rda_static(\n",
    "            save_dir=download_path,\n",
    "            year=year,\n",
    "            month=month,\n",
    "            day=day,\n",
    "            variable=variable,\n",
    "            var_dict=var_nums,\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{variable} already downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6349e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the surface data into a single dataset.\n",
    "if not (download_path / f\"{year}_{month}_{day}-surface-level-0.1deg.nc\").exists():\n",
    "    msl = xr.open_dataset(download_path / f\"msl_{year}_{month}_{day}.grb\", engine=\"cfgrib\")\n",
    "    u10 = xr.open_dataset(download_path / f\"10u_{year}_{month}_{day}.grb\", engine=\"cfgrib\")\n",
    "    v10 = xr.open_dataset(download_path / f\"10v_{year}_{month}_{day}.grb\", engine=\"cfgrib\")\n",
    "    t2m = xr.open_dataset(download_path / f\"2t_{year}_{month}_{day}.grb\", engine=\"cfgrib\")\n",
    "    ds_surf = xr.merge([msl, u10, v10, t2m])\n",
    "    ds_surf.to_netcdf(download_path / f\"{year}_{month}_{day}-surface-level-0.1deg.nc\")\n",
    "\n",
    "# Combine the atmospheric data into a single dataset. This will take a few minutes.\n",
    "if not (download_path / f\"{year}_{month}_{day}-atmospheric-0.1deg.nc\").exists():\n",
    "    q_00 = xr.open_dataset(download_path / f\"q_{year}_{month}_{day}_00.grb\", engine=\"cfgrib\")\n",
    "    q_06 = xr.open_dataset(download_path / f\"q_{year}_{month}_{day}_06.grb\", engine=\"cfgrib\")\n",
    "    q_12 = xr.open_dataset(download_path / f\"q_{year}_{month}_{day}_12.grb\", engine=\"cfgrib\")\n",
    "    q_18 = xr.open_dataset(download_path / f\"q_{year}_{month}_{day}_18.grb\", engine=\"cfgrib\")\n",
    "\n",
    "    t_00 = xr.open_dataset(download_path / f\"t_{year}_{month}_{day}_00.grb\", engine=\"cfgrib\")\n",
    "    t_06 = xr.open_dataset(download_path / f\"t_{year}_{month}_{day}_06.grb\", engine=\"cfgrib\")\n",
    "    t_12 = xr.open_dataset(download_path / f\"t_{year}_{month}_{day}_12.grb\", engine=\"cfgrib\")\n",
    "    t_18 = xr.open_dataset(download_path / f\"t_{year}_{month}_{day}_18.grb\", engine=\"cfgrib\")\n",
    "\n",
    "    u_00 = xr.open_dataset(download_path / f\"u_{year}_{month}_{day}_00.grb\", engine=\"cfgrib\")\n",
    "    u_06 = xr.open_dataset(download_path / f\"u_{year}_{month}_{day}_06.grb\", engine=\"cfgrib\")\n",
    "    u_12 = xr.open_dataset(download_path / f\"u_{year}_{month}_{day}_12.grb\", engine=\"cfgrib\")\n",
    "    u_18 = xr.open_dataset(download_path / f\"u_{year}_{month}_{day}_18.grb\", engine=\"cfgrib\")\n",
    "\n",
    "    v_00 = xr.open_dataset(download_path / f\"v_{year}_{month}_{day}_00.grb\", engine=\"cfgrib\")\n",
    "    v_06 = xr.open_dataset(download_path / f\"v_{year}_{month}_{day}_06.grb\", engine=\"cfgrib\")\n",
    "    v_12 = xr.open_dataset(download_path / f\"v_{year}_{month}_{day}_12.grb\", engine=\"cfgrib\")\n",
    "    v_18 = xr.open_dataset(download_path / f\"v_{year}_{month}_{day}_18.grb\", engine=\"cfgrib\")\n",
    "\n",
    "    z_00 = xr.open_dataset(download_path / f\"z_{year}_{month}_{day}_00.grb\", engine=\"cfgrib\")\n",
    "    z_06 = xr.open_dataset(download_path / f\"z_{year}_{month}_{day}_06.grb\", engine=\"cfgrib\")\n",
    "    z_12 = xr.open_dataset(download_path / f\"z_{year}_{month}_{day}_12.grb\", engine=\"cfgrib\")\n",
    "    z_18 = xr.open_dataset(download_path / f\"z_{year}_{month}_{day}_18.grb\", engine=\"cfgrib\")\n",
    "\n",
    "    ds_atmos = xr.concat(\n",
    "        [\n",
    "            q_00,\n",
    "            q_06,\n",
    "            q_12,\n",
    "            q_18,\n",
    "            t_00,\n",
    "            t_06,\n",
    "            t_12,\n",
    "            t_18,\n",
    "            u_00,\n",
    "            u_06,\n",
    "            u_12,\n",
    "            u_18,\n",
    "            v_00,\n",
    "            v_06,\n",
    "            v_12,\n",
    "            v_18,\n",
    "            z_00,\n",
    "            z_06,\n",
    "            z_12,\n",
    "            z_18,\n",
    "        ],\n",
    "        dim=\"time\",\n",
    "    )\n",
    "    ds_atmos.to_netcdf(download_path / f\"{year}_{month}_{day}-atmospheric-0.1deg.nc\")\n",
    "\n",
    "# Combine the static data into a single dataset.\n",
    "if not (download_path / \"static-0.1deg.nc\").exists():\n",
    "    z = xr.open_dataset(download_path / \"static_z.grb\", engine=\"cfgrib\")\n",
    "    lsm = xr.open_dataset(download_path / \"static_lsm.grb\", engine=\"cfgrib\")\n",
    "    slt = xr.open_dataset(download_path / \"static_slt.grb\", engine=\"cfgrib\")\n",
    "\n",
    "    ds_static = xr.merge([z, lsm, slt])\n",
    "    ds_static.to_netcdf(download_path / \"static-0.1deg.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d8aa4-a16b-481c-b7e5-66764d6e98f1",
   "metadata": {},
   "source": [
    "## Preparing a Batch\n",
    "\n",
    "We convert the downloaded data to an `aurora.Batch`, which is what the model requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fba4fb22-475b-4156-94c8-e61c77a20539",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'level'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 43\u001b[0m\n\u001b[1;32m      9\u001b[0m atmos_vars_ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(\n\u001b[1;32m     10\u001b[0m     download_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mday\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-atmospheric-0.1deg.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnetcdf4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Select this time index in the downloaded data.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m batch \u001b[38;5;241m=\u001b[39m Batch(\n\u001b[1;32m     17\u001b[0m     surf_vars\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2t\u001b[39m\u001b[38;5;124m\"\u001b[39m: surf_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt2m\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10u\u001b[39m\u001b[38;5;124m\"\u001b[39m: surf_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu10\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10v\u001b[39m\u001b[38;5;124m\"\u001b[39m: surf_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv10\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsl\u001b[39m\u001b[38;5;124m\"\u001b[39m: surf_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsl\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     22\u001b[0m     },\n\u001b[1;32m     23\u001b[0m     static_vars\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;66;03m# The static variables are constant, so we just get them for the first time.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfrom_numpy(static_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslt\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfrom_numpy(static_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlsm\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfrom_numpy(static_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlsm\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m     28\u001b[0m     },\n\u001b[1;32m     29\u001b[0m     atmos_vars\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m: atmos_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m: atmos_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m\"\u001b[39m: atmos_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m: atmos_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m: atmos_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     35\u001b[0m     },\n\u001b[1;32m     36\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mMetadata(\n\u001b[1;32m     37\u001b[0m         lat\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfrom_numpy(surf_vars_ds\u001b[38;5;241m.\u001b[39mlatitude\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mcopy()),\n\u001b[1;32m     38\u001b[0m         lon\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfrom_numpy(surf_vars_ds\u001b[38;5;241m.\u001b[39mlongitude\u001b[38;5;241m.\u001b[39mvalues),\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;66;03m# Converting to `datetime64[s]` ensures that the output of `tolist()` gives\u001b[39;00m\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;66;03m# `datetime.datetime`s. Note that this needs to be a tuple of length one:\u001b[39;00m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;66;03m# one value for every batch element.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m         time\u001b[38;5;241m=\u001b[39m(surf_vars_ds\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime64[s]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()[i],),\n\u001b[0;32m---> 43\u001b[0m         atmos_levels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mint\u001b[39m(level) \u001b[38;5;28;01mfor\u001b[39;00m level \u001b[38;5;129;01min\u001b[39;00m \u001b[43matmos_vars_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[38;5;241m.\u001b[39mvalues),\n\u001b[1;32m     44\u001b[0m     ),\n\u001b[1;32m     45\u001b[0m )\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/xarray/core/common.py:286\u001b[0m, in \u001b[0;36mAttrAccessMixin.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mKeyError\u001b[39;00m):\n\u001b[1;32m    285\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m source[name]\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'level'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from aurora import Batch, Metadata\n",
    "\n",
    "static_vars_ds = xr.open_dataset(download_path / \"static-0.1deg.nc\", engine=\"netcdf4\")\n",
    "surf_vars_ds = xr.open_dataset(\n",
    "    download_path / f\"{year}_{month}_{day}-surface-level-0.1deg.nc\", engine=\"netcdf4\"\n",
    ")\n",
    "atmos_vars_ds = xr.open_dataset(\n",
    "    download_path / f\"{year}_{month}_{day}-atmospheric-0.1deg.nc\", engine=\"netcdf4\"\n",
    ")\n",
    "\n",
    "# Only keep 13 pressure levels for atmospheric variables.\n",
    "levels = [50.0, 100.0, 150.0, 200.0, 250.0, 300.0, 400.0, 500.0, 600.0, 700.0, 850.0, 925.0, 1000.0]\n",
    "atmos_vars_ds = atmos_vars_ds.sel(isobaricInhPa=levels)\n",
    "\n",
    "i = 1  # Select this time index in the downloaded data.\n",
    "\n",
    "batch = Batch(\n",
    "    surf_vars={\n",
    "        \"2t\": surf_vars_ds[\"t2m\"].values,\n",
    "        \"10u\": surf_vars_ds[\"u10\"].values,\n",
    "        \"10v\": surf_vars_ds[\"v10\"].values,\n",
    "        \"msl\": surf_vars_ds[\"msl\"].values,\n",
    "    },\n",
    "    static_vars={\n",
    "        # The static variables are constant, so we just get them for the first time.\n",
    "        \"z\": torch.from_numpy(static_vars_ds[\"z\"].values[0]),\n",
    "        \"slt\": torch.from_numpy(static_vars_ds[\"slt\"].values[0]),\n",
    "        \"lsm\": torch.from_numpy(static_vars_ds[\"lsm\"].values[0]),\n",
    "    },\n",
    "    atmos_vars={\n",
    "        \"t\": atmos_vars_ds[\"t\"].values,\n",
    "        \"u\": atmos_vars_ds[\"u\"].values,\n",
    "        \"v\": atmos_vars_ds[\"v\"].values,\n",
    "        \"q\": atmos_vars_ds[\"q\"].values,\n",
    "        \"z\": atmos_vars_ds[\"z\"].values,\n",
    "    },\n",
    "    metadata=Metadata(\n",
    "        lat=torch.from_numpy(surf_vars_ds.latitude.values.copy()),\n",
    "        lon=torch.from_numpy(surf_vars_ds.longitude.values),\n",
    "        # Converting to `datetime64[s]` ensures that the output of `tolist()` gives\n",
    "        # `datetime.datetime`s. Note that this needs to be a tuple of length one:\n",
    "        # one value for every batch element.\n",
    "        time=(surf_vars_ds.time.values.astype(\"datetime64[s]\").tolist()[i],),\n",
    "        atmos_levels=tuple(int(level) for level in atmos_vars_ds.level.values),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6f12fe-1e49-49f0-bf03-bffcea9d1551",
   "metadata": {},
   "source": [
    "## Loading and Running the Model\n",
    "\n",
    "Finally, we are ready to load and run the model and visualise the predictions. We perform a roll-out for two steps, which produces predictions for hours 12:00 and 18:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824be34-060d-422a-addf-841c2c3609b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aurora import Aurora, rollout\n",
    "\n",
    "model = Aurora()\n",
    "model.load_checkpoint(\"wbruinsma/aurora\", \"aurora-0.1-finetuned.ckpt\")\n",
    "\n",
    "model.eval()\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "with torch.inference_mode():\n",
    "    preds = [pred.to(\"cpu\") for pred in rollout(model, batch, steps=2)]\n",
    "\n",
    "model = model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e84170-5802-46ad-b4d8-6eb9bf8c98ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 6.5))\n",
    "\n",
    "for i in range(ax.shape[0]):\n",
    "    pred = preds[i]\n",
    "\n",
    "    ax[i, 0].imshow(pred.surf_vars[\"2t\"][0, 0].numpy() - 273.15, vmin=-50, vmax=50)\n",
    "    ax[i, 0].set_ylabel(str(pred.metadata.time[0]))\n",
    "    if i == 0:\n",
    "        ax[i, 0].set_title(\"Aurora Prediction\")\n",
    "    ax[i, 0].set_xticks([])\n",
    "    ax[i, 0].set_yticks([])\n",
    "\n",
    "    ref = surf_vars_ds[\"2m_temperature\"][2 + i].values[::-1, :]\n",
    "    ax[i, 1].imshow(ref - 273.15, vmin=-50, vmax=50)\n",
    "    if i == 0:\n",
    "        ax[i, 1].set_title(\"HRES T0\")\n",
    "    ax[i, 1].set_xticks([])\n",
    "    ax[i, 1].set_yticks([])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc55217-cc56-4b61-ab18-912251b2178d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
