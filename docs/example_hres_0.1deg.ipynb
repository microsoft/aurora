{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f57a10-13a1-4f66-a734-065fc16b17b2",
   "metadata": {},
   "source": [
    "# Example: Predictions for HRES at 0.1 deg\n",
    "\n",
    "In this example, we will download HRES data for 11 May 2022 from the [Research Data Archive](https://rda.ucar.edu/datasets/d113001/#) at 0.1 degree resolution and run Aurora on this data. We will use the version of Aurora that was fine-tuned on IFS HRES 0.1 degree.\n",
    "\n",
    "Running this notebook requires additional Python packages. You can install these as follows:\n",
    "\n",
    "```\n",
    "pip install xarray zarr netcdf4 cfgrib scipy matplotlib\n",
    "```\n",
    "\n",
    "\n",
    "## Downloading the Data\n",
    "\n",
    "To start, we download the data from [Research Data Archive](https://rda.ucar.edu/datasets/d113001/#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f355c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "from aurora.util import download_hres_rda_atmos, download_hres_rda_static, download_hres_rda_surf\n",
    "\n",
    "# Data will be downloaded here.\n",
    "download_path = Path(\"~/downloads/hres_0.1\")\n",
    "\n",
    "download_path = download_path.expanduser()\n",
    "download_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Day to download. This will download all times for that day.\n",
    "day = \"11\"\n",
    "month = \"05\"\n",
    "year = \"2022\"\n",
    "\n",
    "# Each variable has a number associated with it. This is the number that\n",
    "# will be used in the RDA request.\n",
    "var_nums = {\n",
    "    \"msl\": \"151\",  # Mean sea level pressure\n",
    "    \"10u\": \"165\",  # 10m u-component of wind\n",
    "    \"10v\": \"166\",  # 10m v-component of wind\n",
    "    \"2t\": \"167\",  # 2m temperature\n",
    "    \"z\": \"129\",  # Geopotential\n",
    "    \"t\": \"130\",  # Temperature\n",
    "    \"u\": \"131\",  # u-component of wind (atmos)\n",
    "    \"v\": \"132\",  # v-component of wind (atmos)\n",
    "    \"q\": \"133\",  # Specific humidity (atmos)\n",
    "    \"slt\": \"043\",  # Soil type\n",
    "    \"lsm\": \"172\",  # Land sea mask\n",
    "}\n",
    "\n",
    "surface_vars = [\"msl\", \"10u\", \"10v\", \"2t\"]\n",
    "atmos_vars = [\"z\", \"t\", \"u\", \"v\", \"q\"]\n",
    "static_vars = [\"z\", \"lsm\", \"slt\"]\n",
    "\n",
    "# Download surface variables. We write the downloaded data to cache.\n",
    "for variable in surface_vars:\n",
    "    if not (download_path / f\"{variable}_{year}_{month}_{day}.grb\").exists():\n",
    "        download_hres_rda_surf(\n",
    "            save_dir=download_path,\n",
    "            year=year,\n",
    "            month=month,\n",
    "            day=day,\n",
    "            variable=variable,\n",
    "            var_dict=var_nums,\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{variable} already downloaded\")\n",
    "\n",
    "# Download atmospheric variables. We write the downloaded data to cache.\n",
    "# Each variable has 4 times per day, each of which is a separate file.\n",
    "# This will take a few minutes.\n",
    "for variable in atmos_vars:\n",
    "    for timeofday in [\"00\", \"06\", \"12\", \"18\"]:\n",
    "        if not (download_path / f\"{variable}_{year}_{month}_{day}_{timeofday}.grb\").exists():\n",
    "            download_hres_rda_atmos(\n",
    "                save_dir=download_path,\n",
    "                year=year,\n",
    "                month=month,\n",
    "                day=day,\n",
    "                variable=variable,\n",
    "                var_dict=var_nums,\n",
    "                timeofday=timeofday,\n",
    "            )\n",
    "        else:\n",
    "            print(f\"{variable} at time {timeofday} already downloaded\")\n",
    "\n",
    "# Download static variables. We write the downloaded data to cache.\n",
    "for variable in static_vars:\n",
    "    if not (download_path / f\"static_{variable}.grb\").exists():\n",
    "        download_hres_rda_static(\n",
    "            save_dir=download_path,\n",
    "            year=year,\n",
    "            month=month,\n",
    "            day=day,\n",
    "            variable=variable,\n",
    "            var_dict=var_nums,\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{variable} already downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6349e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the surface data into a single dataset.\n",
    "if not (download_path / f\"{year}_{month}_{day}-surface-level-0.1deg.nc\").exists():\n",
    "    msl = xr.open_dataset(download_path / f\"msl_{year}_{month}_{day}.grb\", engine=\"cfgrib\")\n",
    "    u10 = xr.open_dataset(download_path / f\"10u_{year}_{month}_{day}.grb\", engine=\"cfgrib\")\n",
    "    v10 = xr.open_dataset(download_path / f\"10v_{year}_{month}_{day}.grb\", engine=\"cfgrib\")\n",
    "    t2m = xr.open_dataset(download_path / f\"2t_{year}_{month}_{day}.grb\", engine=\"cfgrib\")\n",
    "    ds_surf = xr.merge([msl, u10, v10, t2m])\n",
    "    ds_surf.to_netcdf(download_path / f\"{year}_{month}_{day}-surface-level-0.1deg.nc\")\n",
    "\n",
    "# Combine the atmospheric data into a single dataset. This will take a few minutes.\n",
    "if not (download_path / f\"{year}_{month}_{day}-atmospheric-0.1deg.nc\").exists():\n",
    "    q_00 = xr.open_dataset(download_path / f\"q_{year}_{month}_{day}_00.grb\", engine=\"cfgrib\")\n",
    "    q_06 = xr.open_dataset(download_path / f\"q_{year}_{month}_{day}_06.grb\", engine=\"cfgrib\")\n",
    "    q_12 = xr.open_dataset(download_path / f\"q_{year}_{month}_{day}_12.grb\", engine=\"cfgrib\")\n",
    "    q_18 = xr.open_dataset(download_path / f\"q_{year}_{month}_{day}_18.grb\", engine=\"cfgrib\")\n",
    "\n",
    "    t_00 = xr.open_dataset(download_path / f\"t_{year}_{month}_{day}_00.grb\", engine=\"cfgrib\")\n",
    "    t_06 = xr.open_dataset(download_path / f\"t_{year}_{month}_{day}_06.grb\", engine=\"cfgrib\")\n",
    "    t_12 = xr.open_dataset(download_path / f\"t_{year}_{month}_{day}_12.grb\", engine=\"cfgrib\")\n",
    "    t_18 = xr.open_dataset(download_path / f\"t_{year}_{month}_{day}_18.grb\", engine=\"cfgrib\")\n",
    "\n",
    "    u_00 = xr.open_dataset(download_path / f\"u_{year}_{month}_{day}_00.grb\", engine=\"cfgrib\")\n",
    "    u_06 = xr.open_dataset(download_path / f\"u_{year}_{month}_{day}_06.grb\", engine=\"cfgrib\")\n",
    "    u_12 = xr.open_dataset(download_path / f\"u_{year}_{month}_{day}_12.grb\", engine=\"cfgrib\")\n",
    "    u_18 = xr.open_dataset(download_path / f\"u_{year}_{month}_{day}_18.grb\", engine=\"cfgrib\")\n",
    "\n",
    "    v_00 = xr.open_dataset(download_path / f\"v_{year}_{month}_{day}_00.grb\", engine=\"cfgrib\")\n",
    "    v_06 = xr.open_dataset(download_path / f\"v_{year}_{month}_{day}_06.grb\", engine=\"cfgrib\")\n",
    "    v_12 = xr.open_dataset(download_path / f\"v_{year}_{month}_{day}_12.grb\", engine=\"cfgrib\")\n",
    "    v_18 = xr.open_dataset(download_path / f\"v_{year}_{month}_{day}_18.grb\", engine=\"cfgrib\")\n",
    "\n",
    "    z_00 = xr.open_dataset(download_path / f\"z_{year}_{month}_{day}_00.grb\", engine=\"cfgrib\")\n",
    "    z_06 = xr.open_dataset(download_path / f\"z_{year}_{month}_{day}_06.grb\", engine=\"cfgrib\")\n",
    "    z_12 = xr.open_dataset(download_path / f\"z_{year}_{month}_{day}_12.grb\", engine=\"cfgrib\")\n",
    "    z_18 = xr.open_dataset(download_path / f\"z_{year}_{month}_{day}_18.grb\", engine=\"cfgrib\")\n",
    "\n",
    "    q = xr.concat([q_00, q_06, q_12, q_18], dim=\"time\")\n",
    "    t = xr.concat([t_00, t_06, t_12, t_18], dim=\"time\")\n",
    "    u = xr.concat([u_00, u_06, u_12, u_18], dim=\"time\")\n",
    "    v = xr.concat([v_00, v_06, v_12, v_18], dim=\"time\")\n",
    "    z = xr.concat([z_00, z_06, z_12, z_18], dim=\"time\")\n",
    "\n",
    "    ds_atmos = xr.merge([q, t, u, v, z])\n",
    "    ds_atmos.to_netcdf(download_path / f\"{year}_{month}_{day}-atmospheric-0.1deg.nc\")\n",
    "\n",
    "# Combine the static data into a single dataset.\n",
    "if not (download_path / \"static-0.1deg.nc\").exists():\n",
    "    z_static = xr.open_dataset(download_path / \"static_z.grb\", engine=\"cfgrib\")\n",
    "    lsm = xr.open_dataset(download_path / \"static_lsm.grb\", engine=\"cfgrib\")\n",
    "    slt = xr.open_dataset(download_path / \"static_slt.grb\", engine=\"cfgrib\")\n",
    "\n",
    "    ds_static = xr.merge([z_static, lsm, slt])\n",
    "    ds_static.to_netcdf(download_path / \"static-0.1deg.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d8aa4-a16b-481c-b7e5-66764d6e98f1",
   "metadata": {},
   "source": [
    "## Preparing a Batch\n",
    "\n",
    "We convert the downloaded data to an `aurora.Batch`, which is what the model requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fba4fb22-475b-4156-94c8-e61c77a20539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from aurora import Batch, Metadata\n",
    "\n",
    "static_vars_ds = xr.open_dataset(download_path / \"static-0.1deg.nc\", engine=\"netcdf4\")\n",
    "surf_vars_ds = xr.open_dataset(\n",
    "    download_path / f\"{year}_{month}_{day}-surface-level-0.1deg.nc\", engine=\"netcdf4\"\n",
    ")\n",
    "atmos_vars_ds = xr.open_dataset(\n",
    "    download_path / f\"{year}_{month}_{day}-atmospheric-0.1deg.nc\", engine=\"netcdf4\"\n",
    ")\n",
    "\n",
    "# Only keep 13 pressure levels for atmospheric variables.\n",
    "levels = [50.0, 100.0, 150.0, 200.0, 250.0, 300.0, 400.0, 500.0, 600.0, 700.0, 850.0, 925.0, 1000.0]\n",
    "atmos_vars_ds = atmos_vars_ds.sel(isobaricInhPa=levels)\n",
    "\n",
    "i = 1  # Select this time index in the downloaded data.\n",
    "\n",
    "# Creating the batch will take a few minutes.\n",
    "batch = Batch(\n",
    "    surf_vars={\n",
    "        \"2t\": torch.from_numpy(surf_vars_ds[\"t2m\"].values),\n",
    "        \"10u\": torch.from_numpy(surf_vars_ds[\"u10\"].values),\n",
    "        \"10v\": torch.from_numpy(surf_vars_ds[\"v10\"].values),\n",
    "        \"msl\": torch.from_numpy(surf_vars_ds[\"msl\"].values),\n",
    "    },\n",
    "    static_vars={\n",
    "        # The static variables are constant, so we just get them for the first time.\n",
    "        \"z\": torch.from_numpy(static_vars_ds[\"z\"].values[0]),\n",
    "        \"slt\": torch.from_numpy(static_vars_ds[\"slt\"].values[0]),\n",
    "        \"lsm\": torch.from_numpy(static_vars_ds[\"lsm\"].values[0]),\n",
    "    },\n",
    "    atmos_vars={\n",
    "        \"t\": torch.from_numpy(atmos_vars_ds[\"t\"].values),\n",
    "        \"u\": torch.from_numpy(atmos_vars_ds[\"u\"].values),\n",
    "        \"v\": torch.from_numpy(atmos_vars_ds[\"v\"].values),\n",
    "        \"q\": torch.from_numpy(atmos_vars_ds[\"q\"].values),\n",
    "        \"z\": torch.from_numpy(atmos_vars_ds[\"z\"].values),\n",
    "    },\n",
    "    metadata=Metadata(\n",
    "        lat=torch.from_numpy(surf_vars_ds.latitude.values.copy()),\n",
    "        lon=torch.from_numpy(surf_vars_ds.longitude.values),\n",
    "        # Converting to `datetime64[s]` ensures that the output of `tolist()` gives\n",
    "        # `datetime.datetime`s. Note that this needs to be a tuple of length one:\n",
    "        # one value for every batch element.\n",
    "        time=(surf_vars_ds.time.values.astype(\"datetime64[s]\").tolist()[i],),\n",
    "        atmos_levels=tuple(int(level) for level in atmos_vars_ds.isobaricInhPa.values),\n",
    "    ),\n",
    ")\n",
    "batch = batch.regrid(res=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "deb6740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.regrid(res=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6f12fe-1e49-49f0-bf03-bffcea9d1551",
   "metadata": {},
   "source": [
    "## Loading and Running the Model\n",
    "\n",
    "Finally, we are ready to load and run the model and visualise the predictions. We perform a roll-out for two steps, which produces predictions for hours 12:00 and 18:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824be34-060d-422a-addf-841c2c3609b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aurora import Aurora, rollout\n",
    "\n",
    "model = Aurora()\n",
    "model.load_checkpoint(\"wbruinsma/aurora\", \"aurora-0.1-finetuned.ckpt\", strict=False)\n",
    "\n",
    "model.eval()\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "with torch.inference_mode():\n",
    "    preds = [pred.to(\"cpu\") for pred in rollout(model, batch, steps=2)]\n",
    "\n",
    "model = model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e84170-5802-46ad-b4d8-6eb9bf8c98ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 6.5))\n",
    "\n",
    "for i in range(ax.shape[0]):\n",
    "    pred = preds[i]\n",
    "\n",
    "    ax[i, 0].imshow(pred.surf_vars[\"2t\"][0, 0].numpy() - 273.15, vmin=-50, vmax=50)\n",
    "    ax[i, 0].set_ylabel(str(pred.metadata.time[0]))\n",
    "    if i == 0:\n",
    "        ax[i, 0].set_title(\"Aurora Prediction\")\n",
    "    ax[i, 0].set_xticks([])\n",
    "    ax[i, 0].set_yticks([])\n",
    "\n",
    "    ref = surf_vars_ds[\"2m_temperature\"][2 + i].values[::-1, :]\n",
    "    ax[i, 1].imshow(ref - 273.15, vmin=-50, vmax=50)\n",
    "    if i == 0:\n",
    "        ax[i, 1].set_title(\"HRES T0\")\n",
    "    ax[i, 1].set_xticks([])\n",
    "    ax[i, 1].set_yticks([])\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
