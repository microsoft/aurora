{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f57a10-13a1-4f66-a734-065fc16b17b2",
   "metadata": {},
   "source": [
    "# Example: Predictions for HRES at 0.1 deg\n",
    "\n",
    "In this example, we will download HRES data for 11 May 2022 from the [Research Data Archive](https://rda.ucar.edu/datasets/d113001/#) at 0.1 degree resolution and run Aurora on this data. We will use the version of Aurora that was fine-tuned on IFS HRES 0.1 degree.\n",
    "\n",
    "Running this notebook requires additional Python packages. You can install these as follows:\n",
    "\n",
    "```\n",
    "pip install cdsapi xarray zarr netcdf4 matplotlib       #TODO: Maybe remove cdsapi later.\n",
    "```\n",
    "\n",
    "Install cfgrib using conda-forge is easiest:\n",
    "```\n",
    "conda install -c conda-forge cfgrib\n",
    "```\n",
    "\n",
    "## Troubleshooting\n",
    "If you get an error regarding `cfgrib`, then make sure you have the `eccodes` library installed correctly:\n",
    "```\n",
    "apt-get install libeccodes-tools\n",
    "```\n",
    "\n",
    "\n",
    "## Downloading the Data\n",
    "\n",
    "To start, we download the data from [Research Data Archive](https://rda.ucar.edu/datasets/d113001/#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f355c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "from aurora.util import download_hres_rda_atmos, download_hres_rda_surf\n",
    "\n",
    "# Data will be downloaded here.\n",
    "download_path = Path(\"~/downloads/hres_0.1\")\n",
    "\n",
    "download_path = download_path.expanduser()\n",
    "download_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Day to download. This will download all times for that day.\n",
    "day = \"11\"\n",
    "month = \"05\"\n",
    "year = \"2022\"\n",
    "\n",
    "# Each variable has a number associated with it. This is the number that\n",
    "# will be used in the RDA request.\n",
    "var_nums = {\n",
    "    \"msl\": \"151\",  # Mean sea level pressure\n",
    "    \"10u\": \"165\",  # 10m u-component of wind\n",
    "    \"10v\": \"166\",  # 10m v-component of wind\n",
    "    \"2t\": \"167\",  # 2m temperature\n",
    "    \"z\": \"129\",  # Geopotential\n",
    "    \"t\": \"130\",  # Temperature\n",
    "    \"u\": \"131\",  # u-component of wind (atmos)\n",
    "    \"v\": \"132\",  # v-component of wind (atmos)\n",
    "    \"q\": \"133\",  # Specific humidity (atmos)\n",
    "}\n",
    "\n",
    "surface_vars = [\"msl\", \"10u\", \"10v\", \"2t\"]\n",
    "atmos_vars = [\"z\", \"t\", \"u\", \"v\", \"q\"]\n",
    "# Download surface variables. We write the downloaded data to cache.\n",
    "for variable in surface_vars:\n",
    "    if not (download_path / f\"{variable}_{year}_{month}_{day}.grb\").exists():\n",
    "        download_hres_rda_surf(\n",
    "            save_dir=download_path,\n",
    "            year=year,\n",
    "            month=month,\n",
    "            day=day,\n",
    "            variable=variable,\n",
    "            var_dict=var_nums,\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{variable} already downloaded\")\n",
    "\n",
    "# Download atmospheric variables. We write the downloaded data to cache.\n",
    "# Each variable has 4 times per day, each of which is a separate file.\n",
    "# This will take a few minutes.\n",
    "for variable in atmos_vars:\n",
    "    if not (download_path / f\"{variable}_{year}_{month}_{day}_00.grb\").exists():\n",
    "        download_hres_rda_atmos(\n",
    "            save_dir=download_path,\n",
    "            year=year,\n",
    "            month=month,\n",
    "            day=day,\n",
    "            variable=variable,\n",
    "            var_dict=var_nums,\n",
    "            timeofday=\"00\",\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{variable} at time 00 already downloaded\")\n",
    "    if not (download_path / f\"{variable}_{year}_{month}_{day}_06.grb\").exists():\n",
    "        download_hres_rda_atmos(\n",
    "            save_dir=download_path,\n",
    "            year=year,\n",
    "            month=month,\n",
    "            day=day,\n",
    "            variable=variable,\n",
    "            var_dict=var_nums,\n",
    "            timeofday=\"06\",\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{variable} at time 06 already downloaded\")\n",
    "    if not (download_path / f\"{variable}_{year}_{month}_{day}_12.grb\").exists():\n",
    "        download_hres_rda_atmos(\n",
    "            save_dir=download_path,\n",
    "            year=year,\n",
    "            month=month,\n",
    "            day=day,\n",
    "            variable=variable,\n",
    "            var_dict=var_nums,\n",
    "            timeofday=\"12\",\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{variable} at time 12 already downloaded\")\n",
    "    if not (download_path / f\"{variable}_{year}_{month}_{day}_18.grb\").exists():\n",
    "        download_hres_rda_atmos(\n",
    "            save_dir=download_path,\n",
    "            year=year,\n",
    "            month=month,\n",
    "            day=day,\n",
    "            variable=variable,\n",
    "            var_dict=var_nums,\n",
    "            timeofday=\"18\",\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{variable} at time 18 already downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6349e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Combine the surface data into a single dataset.\n",
    "if not (download_path / f\"{year}_{month}_{day}-surface-level-0.1deg.nc\").exists():\n",
    "    msl = xr.open_dataset(download_path / f\"msl_{year}_{month}_{day}.grb\", engine=\"cfgrib\")\n",
    "    u10 = xr.open_dataset(download_path / f\"10u_{year}_{month}_{day}.grb\", engine=\"cfgrib\")\n",
    "    v10 = xr.open_dataset(download_path / f\"10v_{year}_{month}_{day}.grb\", engine=\"cfgrib\")\n",
    "    t2m = xr.open_dataset(download_path / f\"2t_{year}_{month}_{day}.grb\", engine=\"cfgrib\")\n",
    "    ds_surf = xr.merge([msl, u10, v10, t2m])\n",
    "    ds_surf.to_netcdf(download_path / f\"{year}_{month}_{day}-surface-level-0.1deg.nc\")\n",
    "\n",
    "# Combine the atmospheric data into a single dataset. This will take a few minutes.\n",
    "# You need TODO: x GB of free space to store the data.\n",
    "if not (download_path / f\"{year}_{month}_{day}-atmospheric-0.1deg.nc\").exists():\n",
    "    q_00 = xr.open_dataset(download_path / f\"q_{year}_{month}_{day}_00.grb\", engine=\"cfgrib\")\n",
    "    q_06 = xr.open_dataset(download_path / f\"q_{year}_{month}_{day}_06.grb\", engine=\"cfgrib\")\n",
    "    q_12 = xr.open_dataset(download_path / f\"q_{year}_{month}_{day}_12.grb\", engine=\"cfgrib\")\n",
    "    q_18 = xr.open_dataset(download_path / f\"q_{year}_{month}_{day}_18.grb\", engine=\"cfgrib\")\n",
    "\n",
    "    t_00 = xr.open_dataset(download_path / f\"t_{year}_{month}_{day}_00.grb\", engine=\"cfgrib\")\n",
    "    t_06 = xr.open_dataset(download_path / f\"t_{year}_{month}_{day}_06.grb\", engine=\"cfgrib\")\n",
    "    t_12 = xr.open_dataset(download_path / f\"t_{year}_{month}_{day}_12.grb\", engine=\"cfgrib\")\n",
    "    t_18 = xr.open_dataset(download_path / f\"t_{year}_{month}_{day}_18.grb\", engine=\"cfgrib\")\n",
    "\n",
    "    u_00 = xr.open_dataset(download_path / f\"u_{year}_{month}_{day}_00.grb\", engine=\"cfgrib\")\n",
    "    u_06 = xr.open_dataset(download_path / f\"u_{year}_{month}_{day}_06.grb\", engine=\"cfgrib\")\n",
    "    u_12 = xr.open_dataset(download_path / f\"u_{year}_{month}_{day}_12.grb\", engine=\"cfgrib\")\n",
    "    u_18 = xr.open_dataset(download_path / f\"u_{year}_{month}_{day}_18.grb\", engine=\"cfgrib\")\n",
    "\n",
    "    v_00 = xr.open_dataset(download_path / f\"v_{year}_{month}_{day}_00.grb\", engine=\"cfgrib\")\n",
    "    v_06 = xr.open_dataset(download_path / f\"v_{year}_{month}_{day}_06.grb\", engine=\"cfgrib\")\n",
    "    v_12 = xr.open_dataset(download_path / f\"v_{year}_{month}_{day}_12.grb\", engine=\"cfgrib\")\n",
    "    v_18 = xr.open_dataset(download_path / f\"v_{year}_{month}_{day}_18.grb\", engine=\"cfgrib\")\n",
    "\n",
    "    z_00 = xr.open_dataset(download_path / f\"z_{year}_{month}_{day}_00.grb\", engine=\"cfgrib\")\n",
    "    z_06 = xr.open_dataset(download_path / f\"z_{year}_{month}_{day}_06.grb\", engine=\"cfgrib\")\n",
    "    z_12 = xr.open_dataset(download_path / f\"z_{year}_{month}_{day}_12.grb\", engine=\"cfgrib\")\n",
    "    z_18 = xr.open_dataset(download_path / f\"z_{year}_{month}_{day}_18.grb\", engine=\"cfgrib\")\n",
    "\n",
    "    ds_atmos = xr.concat(\n",
    "        [\n",
    "            q_00,\n",
    "            q_06,\n",
    "            q_12,\n",
    "            q_18,\n",
    "            t_00,\n",
    "            t_06,\n",
    "            t_12,\n",
    "            t_18,\n",
    "            u_00,\n",
    "            u_06,\n",
    "            u_12,\n",
    "            u_18,\n",
    "            v_00,\n",
    "            v_06,\n",
    "            v_12,\n",
    "            v_18,\n",
    "            z_00,\n",
    "            z_06,\n",
    "            z_12,\n",
    "            z_18,\n",
    "        ],\n",
    "        dim=\"time\",\n",
    "    )\n",
    "    ds_atmos.to_netcdf(download_path / f\"{year}_{month}_{day}-atmospheric-0.1deg.nc\")\n",
    "\n",
    "ds_surf = xr.open_dataset(\n",
    "    download_path / f\"{year}_{month}_{day}-surface-level-0.1deg.nc\", engine=\"netcdf4\"\n",
    ")\n",
    "ds_atmos = xr.open_dataset(\n",
    "    download_path / f\"{year}_{month}_{day}-atmospheric-0.1deg.nc\", engine=\"netcdf4\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Total size of data for 11 May 2022 is {(sys.getsizeof(ds_surf) +\n",
    "                                              sys.getsizeof(ds_atmos))/1e9} GB!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d166a5f",
   "metadata": {},
   "source": [
    "## Downloading Static Variables from ERA5 Data\n",
    "\n",
    "The static variables are not available from the Research Data Archive, so we need to download them from ERA5, just like we did [in the example for ERA5](example_era5.ipynb#downloading-the-data) and [the example for HRES T0](example_hres_t0.ipynb#downloading-the-data)\n",
    "To do so, register an account with the [Climate Data Store](https://cds.climate.copernicus.eu/) and create `$HOME/.cdsapirc` with the following content:\n",
    "\n",
    "```\n",
    "url: https://cds.climate.copernicus.eu/api/v2\n",
    "key: <UID>:<API key>\n",
    "```\n",
    "\n",
    "You can find your UID and API key on your account page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0541bf19-024f-4c76-8666-9d559640156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import cdsapi\n",
    "\n",
    "# Data will be downloaded here.\n",
    "download_path = Path(\"~/downloads/hres_0.1\")\n",
    "\n",
    "c = cdsapi.Client()\n",
    "\n",
    "download_path = download_path.expanduser()\n",
    "download_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the static variables.\n",
    "if not (download_path / \"static.nc\").exists():\n",
    "    c.retrieve(\n",
    "        \"reanalysis-era5-single-levels\",\n",
    "        {\n",
    "            \"product_type\": \"reanalysis\",\n",
    "            \"variable\": [\n",
    "                \"geopotential\",\n",
    "                \"land_sea_mask\",\n",
    "                \"soil_type\",\n",
    "            ],\n",
    "            \"year\": \"2023\",\n",
    "            \"month\": \"01\",\n",
    "            \"day\": \"01\",\n",
    "            \"time\": \"00:00\",\n",
    "            \"format\": \"netcdf\",\n",
    "        },\n",
    "        str(download_path / \"static.nc\"),\n",
    "    )\n",
    "print(\"Static variables downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d8aa4-a16b-481c-b7e5-66764d6e98f1",
   "metadata": {},
   "source": [
    "## Preparing a Batch\n",
    "\n",
    "We convert the downloaded data to an `aurora.Batch`, which is what the model requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4fb22-475b-4156-94c8-e61c77a20539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import xarray as xr\n",
    "\n",
    "from aurora import Batch, Metadata\n",
    "\n",
    "static_vars_ds = xr.open_dataset(download_path / \"static.nc\", engine=\"netcdf4\")\n",
    "surf_vars_ds = xr.open_dataset(\n",
    "    download_path / f\"{year}_{month}_{day}-surface-level-0.1deg.nc\", engine=\"netcdf4\"\n",
    ")\n",
    "atmos_vars_ds = xr.open_dataset(\n",
    "    download_path / f\"{year}_{month}_{day}-atmospheric-0.1deg.nc\", engine=\"netcdf4\"\n",
    ")\n",
    "\n",
    "i = 1  # Select this time index in the downloaded data.\n",
    "\n",
    "\n",
    "batch = Batch(\n",
    "    surf_vars={\n",
    "        \"2t\": surf_vars_ds[\"t2m\"].values,\n",
    "        \"10u\": surf_vars_ds[\"u10\"].values,\n",
    "        \"10v\": surf_vars_ds[\"v10\"].values,\n",
    "        \"msl\": surf_vars_ds[\"msl\"].values,\n",
    "    },\n",
    "    static_vars={\n",
    "        # The static variables are constant, so we just get them for the first time.\n",
    "        \"z\": torch.from_numpy(static_vars_ds[\"z\"].values[0]),\n",
    "        \"slt\": torch.from_numpy(static_vars_ds[\"slt\"].values[0]),\n",
    "        \"lsm\": torch.from_numpy(static_vars_ds[\"lsm\"].values[0]),\n",
    "    },\n",
    "    atmos_vars={\n",
    "        \"t\": atmos_vars_ds[\"t\"].values,\n",
    "        \"u\": atmos_vars_ds[\"u\"].values,\n",
    "        \"v\": atmos_vars_ds[\"v\"].values,\n",
    "        \"q\": atmos_vars_ds[\"q\"].values,\n",
    "        \"z\": atmos_vars_ds[\"z\"].values,\n",
    "    },\n",
    "    metadata=Metadata(\n",
    "        lat=torch.from_numpy(surf_vars_ds.latitude.values.copy()),\n",
    "        lon=torch.from_numpy(surf_vars_ds.longitude.values),\n",
    "        # Converting to `datetime64[s]` ensures that the output of `tolist()` gives\n",
    "        # `datetime.datetime`s. Note that this needs to be a tuple of length one:\n",
    "        # one value for every batch element.\n",
    "        time=(surf_vars_ds.time.values.astype(\"datetime64[s]\").tolist()[i],),\n",
    "        atmos_levels=tuple(int(level) for level in atmos_vars_ds.level.values),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6f12fe-1e49-49f0-bf03-bffcea9d1551",
   "metadata": {},
   "source": [
    "## Loading and Running the Model\n",
    "\n",
    "Finally, we are ready to load and run the model and visualise the predictions. We perform a roll-out for two steps, which produces predictions for hours 12:00 and 18:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824be34-060d-422a-addf-841c2c3609b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aurora import Aurora, rollout\n",
    "\n",
    "model = Aurora()\n",
    "model.load_checkpoint(\"wbruinsma/aurora\", \"aurora-0.1-finetuned.ckpt\")\n",
    "\n",
    "model.eval()\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "with torch.inference_mode():\n",
    "    preds = [pred.to(\"cpu\") for pred in rollout(model, batch, steps=2)]\n",
    "\n",
    "model = model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e84170-5802-46ad-b4d8-6eb9bf8c98ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 6.5))\n",
    "\n",
    "for i in range(ax.shape[0]):\n",
    "    pred = preds[i]\n",
    "\n",
    "    ax[i, 0].imshow(pred.surf_vars[\"2t\"][0, 0].numpy() - 273.15, vmin=-50, vmax=50)\n",
    "    ax[i, 0].set_ylabel(str(pred.metadata.time[0]))\n",
    "    if i == 0:\n",
    "        ax[i, 0].set_title(\"Aurora Prediction\")\n",
    "    ax[i, 0].set_xticks([])\n",
    "    ax[i, 0].set_yticks([])\n",
    "\n",
    "    ref = surf_vars_ds[\"2m_temperature\"][2 + i].values[::-1, :]\n",
    "    ax[i, 1].imshow(ref - 273.15, vmin=-50, vmax=50)\n",
    "    if i == 0:\n",
    "        ax[i, 1].set_title(\"HRES T0\")\n",
    "    ax[i, 1].set_xticks([])\n",
    "    ax[i, 1].set_yticks([])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc55217-cc56-4b61-ab18-912251b2178d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
